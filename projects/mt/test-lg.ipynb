{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9a6358f-ffe9-49b7-ba56-778db60ba456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, TypedDict\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.messages import BaseMessage, FunctionMessage, HumanMessage\n",
    "from langgraph.graph import END, StateGraph\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langchain_community.llms.ollama import Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb06431c-72e7-4d5b-bf15-ff6df717ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37c09cd9-6c4f-4a1d-81be-fc963db4758d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tool to use in graph\n",
    "@tool\n",
    "def handoff_to_flight_delay_agent(data):\n",
    "    \"\"\"\n",
    "    Hands off to the FlightDelayAnalysisAgent.\n",
    "    \"\"\"\n",
    "    flight_delay_agent = FlightDelayAnalysisAgent()\n",
    "    return flight_delay_agent.process_data(data)\n",
    "\n",
    "@tool\n",
    "def handoff_to_query_understanding_agent(data):\n",
    "    \"\"\"\n",
    "    Hands off to the QueryUnderstandingAgent.\n",
    "    \"\"\"\n",
    "    query_understanding_agent = QueryUnderstandingAgent()\n",
    "    return query_understanding_agent.process_data(data)\n",
    "\n",
    "@tool\n",
    "def process_general_query(data, query):\n",
    "    \"\"\"\n",
    "    Handles general queries using the LLM.\n",
    "    \"\"\"\n",
    "    general_query_prompt = f\"\"\"\n",
    "    You are a helpful assistant that can answer general questions about the flight data.\n",
    "\n",
    "    Here is the schema of the data:\n",
    "    # ... (You might want to include schema information here, similar to what's done in NaturalLanguageQueryingAgent) ...\n",
    "\n",
    "    The user is asking: \"{query}\"\n",
    "\n",
    "    Provide a concise answer based on your understanding of the data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        llm_response = generate_analysis(general_query_prompt)\n",
    "        return {\"response\": llm_response}\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in process_general_query: {e}\")\n",
    "        return {\"response\": f\"Error processing query: {str(e)}\"}\n",
    "\n",
    "@tool\n",
    "def analyze_schema(data):\n",
    "    \"\"\"\n",
    "    Analyzes the schema of the provided data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        schema_agent = SchemaAnalysisAgent()\n",
    "        return schema_agent.process_data(data)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in analyze_schema: {e}\")\n",
    "        return {\"error\": f\"Schema analysis failed: {str(e)}\"}\n",
    "\n",
    "@tool\n",
    "def analyze_data_types(data):\n",
    "    \"\"\"\n",
    "    Analyzes the data types and characteristics of the data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        type_agent = DataTypeAnalysisAgent()\n",
    "        return type_agent.process_data(data)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in analyze_data_types: {e}\")\n",
    "        return {\"error\": f\"Data type analysis failed: {str(e)}\"}\n",
    "\n",
    "@tool\n",
    "def process_natural_language_query(data, query):\n",
    "    \"\"\"\n",
    "    Processes natural language queries by translating them into executable code.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        nl_query_agent = NaturalLanguageQueryingAgent(\n",
    "            SchemaAnalysisAgent(), DataTypeAnalysisAgent()\n",
    "        )\n",
    "        return nl_query_agent.process_data(data, query)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in process_natural_language_query: {e}\")\n",
    "        return {\"error\": f\"Query processing failed: {str(e)}\"}\n",
    "\n",
    "# Define the list of tools for the agent\n",
    "tools = [\n",
    "    handoff_to_flight_delay_agent,\n",
    "    handoff_to_query_understanding_agent,\n",
    "    process_general_query,\n",
    "    analyze_schema,\n",
    "    analyze_data_types,\n",
    "    process_natural_language_query,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01496f2a-e0a1-4b38-b6f6-82468b1756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchemaAnalysisAgent:\n",
    "    \"\"\"Agent for analyzing the schema and data types of the input data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "    async def process_data(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        try:\n",
    "            schema_info = {}\n",
    "\n",
    "            # Add column names and data types\n",
    "            schema_info[\"columns\"] = {col: str(data[col].dtype) for col in data.columns}\n",
    "\n",
    "            # Basic descriptive statistics\n",
    "            schema_info[\"stats\"] = (\n",
    "                data.describe(include=\"all\", datetime_is_numeric=True).to_dict()\n",
    "            )\n",
    "\n",
    "            # Generate LLM analysis for schema description\n",
    "            schema_prompt = f\"\"\"\n",
    "            You are a data analyst tasked with explaining the schema of a dataset. \n",
    "            The dataset has the following columns and data types:\n",
    "\n",
    "            {json.dumps(schema_info['columns'], indent=2)}\n",
    "\n",
    "            Provide a concise description of the dataset, including:\n",
    "            1. The overall purpose of the dataset.\n",
    "            2. A brief explanation of each column and its meaning.\n",
    "            3. Any potential relationships between columns.\n",
    "\n",
    "            Additionally, here are some basic statistics about the columns:\n",
    "            {json.dumps(schema_info['stats'], indent=2)}\n",
    "            \n",
    "            Use these statistics to further explain the data in each column.\n",
    "            Be clear and concise, using natural language that a non-technical user can understand.\n",
    "            \"\"\"\n",
    "\n",
    "            llm_schema_description = await self.generate_analysis(schema_prompt)\n",
    "\n",
    "            return {\n",
    "                \"schema\": schema_info,\n",
    "                \"schema_description\": llm_schema_description,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in SchemaAnalysisAgent.process_data: {e}\")\n",
    "            return {\"error\": f\"Schema analysis failed: {str(e)}\"}\n",
    "\n",
    "    async def generate_analysis(self, prompt: str) -> str:\n",
    "        \"\"\"Helper function to generate analysis using the LLM.\"\"\"\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_analysis: {e}\")\n",
    "            return f\"Error generating analysis: {str(e)}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0cb106c5-cd23-4e36-97d5-1cf646a6d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTypeAnalysisAgent:\n",
    "    \"\"\"Agent for analyzing data types and characteristics of the data.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "    async def process_data(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        try:\n",
    "            type_info = {}\n",
    "\n",
    "            for col in data.columns:\n",
    "                type_info[col] = {}\n",
    "                type_info[col][\"dtype\"] = str(data[col].dtype)\n",
    "                type_info[col][\"unique_values\"] = data[col].nunique()\n",
    "                type_info[col][\"is_unique\"] = data[col].is_unique\n",
    "                type_info[col][\"missing_percentage\"] = (\n",
    "                    (data[col].isnull().sum() / len(data)) * 100\n",
    "                )\n",
    "\n",
    "                if pd.api.types.is_numeric_dtype(data[col]):\n",
    "                    type_info[col][\"min\"] = data[col].min()\n",
    "                    type_info[col][\"max\"] = data[col].max()\n",
    "                    type_info[col][\"mean\"] = data[col].mean()\n",
    "                    type_info[col][\"median\"] = data[col].median()\n",
    "                elif pd.api.types.is_string_dtype(data[col]):\n",
    "                    type_info[col][\"value_counts\"] = (\n",
    "                        data[col].value_counts().head(10).to_dict()\n",
    "                    )\n",
    "\n",
    "            type_prompt = f\"\"\"\n",
    "            You are a data analyst tasked with explaining the data types and characteristics of a dataset.\n",
    "\n",
    "            Here is information about each column:\n",
    "            {json.dumps(type_info, indent=2)}\n",
    "\n",
    "            Provide a concise analysis for each column, including:\n",
    "            1. An interpretation of its data type.\n",
    "            2. Whether the column could be a unique identifier.\n",
    "            3. The distribution of values (ranges for numerical, common values for categorical).\n",
    "            4. The percentage of missing values and potential implications.\n",
    "\n",
    "            Use natural language and be clear and concise.\n",
    "            \"\"\"\n",
    "\n",
    "            llm_type_description = await self.generate_analysis(type_prompt)\n",
    "\n",
    "            return {\n",
    "                \"data_types\": type_info,\n",
    "                \"type_description\": llm_type_description,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in DataTypeAnalysisAgent.process_data: {e}\")\n",
    "            return {\"error\": f\"Data type analysis failed: {str(e)}\"}\n",
    "\n",
    "    async def generate_analysis(self, prompt: str) -> str:\n",
    "        \"\"\"Helper function to generate analysis using the LLM.\"\"\"\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_analysis: {e}\")\n",
    "            return f\"Error generating analysis: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe254848-7bcc-4251-8cb1-febf46408565",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlightDelayAnalysisAgent:\n",
    "    \"\"\"Agent for analyzing flight delays.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "    async def process_data(self, data: pd.DataFrame) -> Dict[str, Any]:\n",
    "        try:\n",
    "            if \"arvl_dlay_cat_cd\" in data.columns:\n",
    "                avg_arrival_delay = data[\"arvl_dlay_cat_cd\"].mean()\n",
    "            else:\n",
    "                avg_arrival_delay = \"Column 'arvl_dlay_cat_cd' not found in data\"\n",
    "\n",
    "            analysis_prompt = f\"\"\"\n",
    "            Analyze the following flight delay statistics:\n",
    "            - Average Arrival Delay: {avg_arrival_delay}\n",
    "            - ... (other delay-related statistics) ...\n",
    "\n",
    "            Provide insights into the causes and patterns of flight delays.\n",
    "            \"\"\"\n",
    "            llm_analysis = await self.generate_analysis(analysis_prompt)\n",
    "\n",
    "            return {\n",
    "                \"avg_arrival_delay\": avg_arrival_delay,\n",
    "                \"llm_analysis\": llm_analysis,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in FlightDelayAnalysisAgent.process_data: {e}\")\n",
    "            return {\"error\": f\"Flight delay analysis failed: {str(e)}\"}\n",
    "\n",
    "    async def generate_analysis(self, prompt: str) -> str:\n",
    "        \"\"\"Helper function to generate analysis using the LLM.\"\"\"\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_analysis: {e}\")\n",
    "            return f\"Error generating analysis: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cbfe9c-56b3-4ed8-85f6-197893171233",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryUnderstandingAgent:\n",
    "    \"\"\"Agent that breaks down complex queries into smaller sub-queries.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.llm = Ollama(model=\"llama3.2:1b\")\n",
    "\n",
    "    async def process_data(self, data: pd.DataFrame, query: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            decomposition_prompt = f\"\"\"\n",
    "            You are an expert at breaking down complex data analysis questions into smaller, manageable sub-queries.\n",
    "\n",
    "            The user has asked the following complex question: \"{query}\"\n",
    "\n",
    "            Break this question down into a series of simpler questions that can be answered individually using a dataset. \n",
    "            Output these sub-questions as a JSON list, like so:\n",
    "\n",
    "            ```json\n",
    "            [\n",
    "                \"Sub-question 1\",\n",
    "                \"Sub-question 2\",\n",
    "                \"Sub-question 3\"\n",
    "            ]\n",
    "            ```\n",
    "            \"\"\"\n",
    "\n",
    "            llm_response = await self.generate_analysis(decomposition_prompt)\n",
    "\n",
    "            try:\n",
    "                sub_queries = json.loads(llm_response)\n",
    "            except json.JSONDecodeError:\n",
    "                sub_queries = []\n",
    "                logger.error(\"Could not parse sub-queries from LLM response.\")\n",
    "\n",
    "            return {\n",
    "                \"original_query\": query,\n",
    "                \"sub_queries\": sub_queries,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in QueryUnderstandingAgent.process_data: {e}\")\n",
    "            return {\"error\": f\"Query understanding failed: {str(e)}\"}\n",
    "\n",
    "    async def generate_analysis(self, prompt: str) -> str:\n",
    "        \"\"\"Helper function to generate analysis using the LLM.\"\"\"\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_analysis: {e}\")\n",
    "            return f\"Error generating analysis: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fc5922-95cb-4008-bfee-7e2917e4c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaturalLanguageQueryingAgent:\n",
    "    \"\"\"Agent for handling natural language queries about the data.\"\"\"\n",
    "\n",
    "    def __init__(self, schema_agent: SchemaAnalysisAgent, type_agent: DataTypeAnalysisAgent):\n",
    "        self.llm = Ollama(model=\"llama3.2:1b\")\n",
    "        self.schema_agent = schema_agent\n",
    "        self.type_agent = type_agent\n",
    "\n",
    "    async def process_data(self, data: pd.DataFrame, query: str) -> Dict[str, Any]:\n",
    "        try:\n",
    "            schema_results = await self.schema_agent.process_data(data.copy())\n",
    "            type_results = await self.type_agent.process_data(data.copy())\n",
    "\n",
    "            schema_info = schema_results[\"schema\"]\n",
    "            schema_description = schema_results[\"schema_description\"]\n",
    "            type_info = type_results[\"data_types\"]\n",
    "            type_description = type_results[\"type_description\"]\n",
    "\n",
    "            query_prompt = f\"\"\"\n",
    "            You are a data analyst who can translate natural language queries into Python code.\n",
    "\n",
    "            Here is the schema of the DataFrame:\n",
    "            {json.dumps(schema_info, indent=2)}\n",
    "            \n",
    "            Schema Description:\n",
    "            {schema_description}\n",
    "\n",
    "            Data Types:\n",
    "            {json.dumps(type_info, indent=2)}\n",
    "\n",
    "            Type Description:\n",
    "            {type_description}\n",
    "\n",
    "            The user wants to know: \"{query}\"\n",
    "\n",
    "            Generate Python code using pandas to answer this query.\n",
    "            Assume the DataFrame is named 'data'.\n",
    "            \"\"\"\n",
    "\n",
    "            generated_code = await self.generate_analysis(query_prompt)\n",
    "\n",
    "            local_vars = {\"data\": data.copy(), \"result\": None}\n",
    "            try:\n",
    "                exec(generated_code, {}, local_vars)\n",
    "                result = local_vars[\"result\"]\n",
    "                if isinstance(result, pd.DataFrame):\n",
    "                    result = result.to_string()\n",
    "            except Exception as e:\n",
    "                result = f\"Error executing generated code: {e}\"\n",
    "\n",
    "            return {\n",
    "                \"query\": query,\n",
    "                \"generated_code\": generated_code,\n",
    "                \"result\": result,\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in NaturalLanguageQueryingAgent.process_data: {e}\")\n",
    "            return {\"error\": f\"Natural language querying failed: {str(e)}\"}\n",
    "\n",
    "    async def generate_analysis(self, prompt: str) -> str:\n",
    "        \"\"\"Helper function to generate analysis using the LLM.\"\"\"\n",
    "        try:\n",
    "            messages = [{\"role\": \"system\", \"content\": prompt}]\n",
    "            response = self.llm.invoke(messages)\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in generate_analysis: {e}\")\n",
    "            return f\"Error generating analysis: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36a03868-2fab-4ddd-ab58-56ec5b914662",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    \"\"\"Represents the state of our agent.\"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "    next: str\n",
    "    data: pd.DataFrame\n",
    "    query: Optional[str] = None\n",
    "    sender: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2e3e9e9-d9d0-40e1-ab5d-9c3c2e78b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(log_table_path: str, fact_table_path: str) -> pd.DataFrame:\n",
    "    \"\"\"Loads and preprocesses data from the log and fact tables.\"\"\"\n",
    "    try:\n",
    "        log_df = pd.read_csv(log_table_path)\n",
    "        fact_df = pd.read_csv(fact_table_path)\n",
    "\n",
    "        # Data Cleaning\n",
    "        log_df.columns = log_df.columns.str.lower()\n",
    "        fact_df.columns = fact_df.columns.str.lower()\n",
    "        \n",
    "        # Convert date columns\n",
    "        for df in [log_df, fact_df]:\n",
    "            date_columns = [col for col in df.columns if col.endswith((\"_dt\", \"_dttm\"))]\n",
    "            for col in date_columns:\n",
    "                df[col] = pd.to_datetime(df[col], errors=\"coerce\")\n",
    "\n",
    "        # Join tables\n",
    "        common_columns = list(set(log_df.columns).intersection(fact_df.columns))\n",
    "        merged_df = pd.merge(log_df, fact_df, on=common_columns, how=\"inner\")\n",
    "        \n",
    "        # Remove duplicate columns\n",
    "        merged_df = merged_df.loc[:, ~merged_df.columns.duplicated()]\n",
    "\n",
    "        return merged_df\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading or merging data: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf866a2-9042-426c-94af-859fe8cca45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_node(state: AgentState, data: pd.DataFrame) -> Dict:\n",
    "    \"\"\"Processes the user query and determines the next step.\"\"\"\n",
    "    try:\n",
    "        prompt = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"You are a helpful assistant that can answer general questions about flight data.\"),\n",
    "            (\"human\", \"{input}\"),\n",
    "        ])\n",
    "        \n",
    "        llm = Ollama(model=\"llama3.2:1b\").bind_tools(tools)\n",
    "        chain = prompt | llm\n",
    "        result = chain.invoke({\"input\": state[\"query\"]}, config={\"run_name\": \"agent\"})\n",
    "\n",
    "        content = result.content if not isinstance(result.content, str) else result.content\n",
    "\n",
    "        if result.additional_kwargs and \"tool_calls\" in result.additional_kwargs:\n",
    "            calls = result.additional_kwargs[\"tool_calls\"]\n",
    "            logger.info(f\"Agent identified tool calls: {calls}\")\n",
    "\n",
    "            if calls:\n",
    "                function_name = calls[0][\"function\"][\"name\"]\n",
    "                next_step = {\n",
    "                    \"handoff_to_flight_delay_agent\": \"flight_delay_analysis\",\n",
    "                    \"handoff_to_query_understanding_agent\": \"query_understanding\",\n",
    "                    \"process_general_query\": \"general_query\",\n",
    "                    \"analyze_schema\": \"schema_analysis\",\n",
    "                    \"analyze_data_types\": \"data_type_analysis\",\n",
    "                    \"process_natural_language_query\": \"natural_language_querying\"\n",
    "                }.get(function_name, END)\n",
    "            else:\n",
    "                next_step = END\n",
    "\n",
    "            messages = []\n",
    "            if content:\n",
    "                messages.append(HumanMessage(content=content))\n",
    "            for call in calls:\n",
    "                messages.append(\n",
    "                    FunctionMessage(name=call[\"function\"][\"name\"], \n",
    "                                  content=json.dumps(call[\"function\"]))\n",
    "                )\n",
    "\n",
    "            return {\"messages\": messages, \"data\": data, \"next\": next_step}\n",
    "        else:\n",
    "            return {\"messages\": [HumanMessage(content=content)], \"data\": data, \"next\": END}\n",
    "            \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in agent_node: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")], \n",
    "            \"data\": data, \n",
    "            \"next\": END\n",
    "        }\n",
    "\n",
    "# Agent functions\n",
    "async def flight_delay_analysis_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles flight delay analysis.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        agent = FlightDelayAnalysisAgent()\n",
    "        result = await agent.process_data(data)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=result[\"llm_analysis\"])],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in flight_delay_analysis_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "\n",
    "async def query_understanding_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles query understanding.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        query = state[\"query\"]\n",
    "        agent = QueryUnderstandingAgent()\n",
    "        result = await agent.process_data(data, query)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=json.dumps(result))],\n",
    "            \"data\": data,\n",
    "            \"next\": \"natural_language_querying\" if result.get(\"sub_queries\") else END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in query_understanding_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "\n",
    "async def general_query_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles general queries.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        query = state[\"query\"]\n",
    "        result = process_general_query(data, query)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=result[\"response\"])],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in general_query_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "\n",
    "async def schema_analysis_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles schema analysis.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        agent = SchemaAnalysisAgent()\n",
    "        result = await agent.process_data(data)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=result[\"schema_description\"])],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in schema_analysis_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "\n",
    "async def data_type_analysis_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles data type analysis.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        agent = DataTypeAnalysisAgent()\n",
    "        result = await agent.process_data(data)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=result[\"type_description\"])],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in data_type_analysis_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "\n",
    "async def natural_language_querying_agent(state: AgentState) -> Dict:\n",
    "    \"\"\"Handles natural language querying.\"\"\"\n",
    "    try:\n",
    "        data = state[\"data\"]\n",
    "        query = state[\"query\"]\n",
    "        agent = NaturalLanguageQueryingAgent(\n",
    "            SchemaAnalysisAgent(), DataTypeAnalysisAgent()\n",
    "        )\n",
    "        result = await agent.process_data(data, query)\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=result[\"result\"])],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in natural_language_querying_agent: {e}\")\n",
    "        return {\n",
    "            \"messages\": [HumanMessage(content=f\"Error: {str(e)}\")],\n",
    "            \"data\": data,\n",
    "            \"next\": END,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c11b13-6ae4-4933-ae35-fc7be39c8fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    \"\"\"Main function to run the agent system.\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        log_table_path = \"log-table.csv\"\n",
    "        fact_table_path = \"fact-table.csv\"\n",
    "        data = load_data(log_table_path, fact_table_path)\n",
    "        \n",
    "        if data is None:\n",
    "            raise ValueError(\"Failed to load data\")\n",
    "\n",
    "        # Create workflow\n",
    "        workflow = StateGraph(AgentState)\n",
    "        \n",
    "        # Add nodes\n",
    "        workflow.add_node(\"agent\", lambda state: agent_node(state, state[\"data\"]))\n",
    "        workflow.add_node(\"flight_delay_analysis\", flight_delay_analysis_agent)\n",
    "        workflow.add_node(\"query_understanding\", query_understanding_agent)\n",
    "        workflow.add_node(\"general_query\", general_query_agent)\n",
    "        workflow.add_node(\"schema_analysis\", schema_analysis_agent)\n",
    "        workflow.add_node(\"data_type_analysis\", data_type_analysis_agent)\n",
    "        workflow.add_node(\"natural_language_querying\", natural_language_querying_agent)\n",
    "\n",
    "        # Set entry point and edges\n",
    "        workflow.set_entry_point(\"agent\")\n",
    "        \n",
    "        # Add edges\n",
    "        for node in [\"flight_delay_analysis\", \"general_query\", \"schema_analysis\", \n",
    "                    \"data_type_analysis\", \"natural_language_querying\"]:\n",
    "            workflow.add_edge(node, END)\n",
    "        \n",
    "        workflow.add_edge(\"query_understanding\", \"natural_language_querying\")\n",
    "\n",
    "        # Add conditional edges\n",
    "        workflow.add_conditional_edges(\n",
    "            \"agent\",\n",
    "            lambda x: x[\"next\"],\n",
    "            {\n",
    "                \"flight_delay_analysis\": \"flight_delay_analysis\",\n",
    "                \"query_understanding\": \"query_understanding\",\n",
    "                \"general_query\": \"general_query\",\n",
    "                \"schema_analysis\": \"schema_analysis\",\n",
    "                \"data_type_analysis\": \"data_type_analysis\",\n",
    "                \"natural_language_querying\": \"natural_language_querying\",\n",
    "                END: END,\n",
    "            },\n",
    "        )\n",
    "\n",
    "        # Compile and run\n",
    "        app = workflow.compile()\n",
    "\n",
    "        # Example queries\n",
    "        test_queries = [\n",
    "            \"what is the schema of this dataset\",\n",
    "            \"what are the datatypes in this dataset\",\n",
    "            \"analyze flight delays\",\n",
    "            \"what is the average arrival delay\"\n",
    "        ]\n",
    "\n",
    "        for query in test_queries:\n",
    "            try:\n",
    "                inputs = {\n",
    "                    \"query\": query,\n",
    "                    \"data\": data,\n",
    "                    \"messages\": [],\n",
    "                }\n",
    "                response = app.invoke(inputs)\n",
    "                print(f\"\\nQuery: {query}\")\n",
    "                print(\"Response:\", response)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing query '{query}': {e}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in main: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    asyncio.run(main())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
